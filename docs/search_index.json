[
["index.html", "The Covid19R Project Documentation Welcome to the Covid19R Project Documentation! How can I get access to the data? What are your standards? I want to contribute!", " The Covid19R Project Documentation Rami Krispin, Amanda Dobbyn, Jarrett Byrnes 2020-04-30 Welcome to the Covid19R Project Documentation! The Covid19R Project is an attempt to provide a set of standards for creating tidy Covid-19 related data distribution packages as well as a centralized method for then redistributing the data sets themselves within R. We’re trying to build a community with interoperable data standards in order to allow anyone using R to derive novel insights about this. global pandemic. In the documentation for the Covid19R Project, we detail what the project is, how to be a part of it, and what minimal tidy standards we want data packages to conform to in order to bring all of our data together! How can I get access to the data? If you want to jump in and just get access to the data, install the covid19R package. You can read up on how to use it in The Covid19R Package. What are your standards? We’ve attempted to create a unified tidy Data Format Standard which you can read about. Packages employ a Standardized Vocabulary, and all implement a set of Standardized Package Functions in order to make it easier for us to use packages to harvest the data for central distribution. I want to contribute! If you want to conribute to the project, that’s wonderful! Check out our section on Building a New Data Package and the associated additional documentation. If you’d like to check out what we already have, check out the Packages Part of the Project! Otherwise, read on to learn more. "],
["intro.html", "Chapter 1 Introduction 1.1 Origins 1.2 Why this project? 1.3 Why many small data packages?", " Chapter 1 Introduction 1.1 Origins The Covid19R Project started with the creation of the coronavirus R package by Rami Krispin. This package ulled from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus repository. Quickly, many members of the R community jumped in, both using it and contributing small additions and fixes - particularly as the JHU Data morphed quite a bit in the early days of the pandemic. At the same time, multiple other data aggregation efforts sprang up, from the Corona Data Scraper project, which provided automated scraping of many many sources online to the Covid Tracking Project, supported by multiple different media organizations. These are but a few of the data sources available. 1.2 Why this project? As with any massive effort with multiple distributed data sources, the datset interface varies wildly from dataset to dataset. Moreover, different datasets track different things - sometimes for the same place. Researchers, however, often want to bring multiple datasets together swiftly in a standardized easy to user format. Moreover, doing it inside of an R package environment provides ease of use for data analysts, so that they do not have to spend the time searching the web, downloading, and aggregating data sets. The Covid19R project aims to create a unified interface to as many data sources as possible, providing a standardized tidy data format across all sets. We aim to do this by having individuals (us or other contributors - like you!) write independent data packages for different datasets. These packages will have a handful of commonly specified functions that will read in and reshape the data into our standard format. After submitting the name of the package to us by filing an issue on the covid19R package, we will add the package to our database, which will update all data sets daily. End-users can then access all data sets and information about them via the covid19R package, which has minimal dependencies (we know that processing some of those datasets in can require A LOT of data manipulation). Here in these documents, we lay out both our data standard as well as a general guide to onboarding a new data package. 1.3 Why many small data packages? One of the first questions that comes up is, why are we creating a project with many small data packages and once centralized distribution package - the covid19R package. This might at first seem overly complex. We’ve structured the project this was in order to ensure robust data delivery based on our own encounters with creating and maintaining data distribution packages, as well as efforts to add new data sets to the mix within R. Data refresh fails. Often. For many different data sets. We are in a time where new data sets are coming online daily, and data providers are revising their own data standards far more often than is optimal. This is not likely to change for some time. Many smaller data distribution packages ensures that, when one data source fails, they don’t all fail. Lowering the bar on requirements for end-users. By providing end-users access to all data sets via the covid19R package, we can give users a minimal dependency structure in order to access the data. Many data sources require extensive wrangling with multiple packages, often requiring a complex dependency tree. Rather than have users have to worry about all of that, creating multiple opportunities for points of failure, we opted to provide end-users something simple. Reducing the need for end-users to stay up-to-date. If we are going to persue a multiple small data packages in order to reduce the possibility of data source failures causing a whole data distribution package from crashing down on everyone’s heads, then we certaintly don’t want to place the burdern on end-users to keep up to date with the latest and greatest new data source packages coming in to R. Heck, many of them may end up just on GitHub, and not even go to CRAN (although we hope they do!) Who has time for keeping track of that! Rather, by using the covid19R package, they can see what data is there at any time, filter to what they want, and move forward with salient analyses. Embracing community. Honestly, building data packages is fun. And all sorts of interesting issues come up along the way. We are excited and hopeful that this effort creates a community of R users who build data acquisition packages. We have a low bar for what we require from each data package, which should make entry to being part of the project easy! Heck, we’re hopeful that some groups out there use this project as a target for hackathons! Further, we hope that people find this a simple way to engage with the ongoing pandemic in a way that is meaningful to them, and does some good. It has certainly been such an experience for the three of us. Providing an onramp to package development for new learners. Building your first R package is hard. And yet, lots of people want to do it. We’ve tried to provide a wealth of materials to help those new to package building an easy first time out, as it were. Lots of people are trying to brush up on their skills right now, and hopefully we can provide a useful point of entry for interested folk to learn something about package development, or for R-user groups or courses to have a great target for a learning hackathon. "],
["the-covid19r-package.html", "Chapter 2 The Covid19R Package 2.1 Finding out what data we have with get_covid19_data_info() 2.2 Downloading a dataset with get_covid19_dataset() 2.3 Examining controlled vocabulary with get_covid19_controlled_vocab()", " Chapter 2 The Covid19R Package The covid19R package is written to access the data collected by packages that are part of the Covid19R project. It has minimal dependencies, and does not require you to install any of the other data access packages. Rather, it queries our building database of standardized tidy datasets, allowing you to search what is available, and then directly download the datasets that have been updated in the previous 6 hours. library(covid19R) #for examples library(dplyr) 2.1 Finding out what data we have with get_covid19_data_info() To see what data is available, get_covid19_data_info() returns a tibble of all data sets that are available, as well as information about each. This is the same information that individual data packages have returned with their own get_info_*() functions discussed in Standardized Package Functions. In addition, it provides information on when the data was last updated, and if the data package is currently able to acquire data, or is failing. Here is what we have at the time of writing this documentation. dat_info &lt;- get_covid19_data_info() dat_info %&gt;% knitr::kable() %&gt;% kableExtra::kable_styling( bootstrap_options = c(&quot;striped&quot;,&quot;condensed&quot;, &quot;responsive&quot;)) %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;100%&quot;) data_set_name package_name function_to_get_data data_details data_url license_url data_types location_types spatial_extent has_geospatial_info get_info_passing refresh_status last_update covid19nytimes_states covid19nytimes refresh_covid19nytimes_states Open Source data from the New York Times on distribution of confirmed Covid-19 cases and deaths in the US States. For more, see https://www.nytimes.com/article/coronavirus-county-data-us.html or the readme at https://github.com/nytimes/covid-19-data. https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv https://github.com/nytimes/covid-19-data/blob/master/LICENSE cases_total, deaths_total state country FALSE TRUE Passed 2020-04-26 covid19nytimes_counties covid19nytimes refresh_covid19nytimes_counties Open Source data from the New York Times on distribution of confirmed Covid-19 cases and deaths in the US by County. For more, see https://www.nytimes.com/article/coronavirus-county-data-us.html or the readme at https://github.com/nytimes/covid-19-data. https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv https://github.com/nytimes/covid-19-data/blob/master/LICENSE cases_total, deaths_total state country FALSE TRUE Passed 2020-04-26 covid19france covid19france refresh_covid19france Open Source data from opencovid19-fr on distribution of confirmed Covid-19 cases and deaths in the US States. For more, see https://github.com/opencovid19-fr/data. https://raw.githubusercontent.com/opencovid19-fr/data/master/dist/chiffres-cles.csv https://github.com/opencovid19-fr/data/blob/master/LICENSE confirmed, dead, icu, hospitalized, recovered, discovered county, region, country, overseas collectivity country FALSE TRUE Passed 2020-04-27 CanadaC19_cases CanadaC19 refresh_CanadaC19_cases Open Source data from multiple public reporting data throughout Canada. For more, see https://github.com/ishaberry/Covid19Canada. https://raw.githubusercontent.com/ishaberry/Covid19Canada/master/cases.csv https://github.com/debusklaneml/CanadaC19/blob/master/LICENSE cases_new state state FALSE TRUE Passed 2020-04-26 covid19us covid19us refresh_covid19us Open Source data from COVID Tracking Project on the distribution of Covid-19 cases and deaths in the US. For more, see https://github.com/opencovid19-fr/data. https://covidtracking.com/api https://github.com/aedobbyn/covid19us/blob/master/LICENSE.md positive, negative, pending, hospitalized_currently, hospitalized_cumulative, in_icu_currently, in_icu_cumulative, on_ventilator_currently, on_ventilator_cumulative, recovered, death, hospitalized, total, total_test_results, death_increase, hospitalized_increase, negative_increase, positive_increase, total_test_results_increase state country FALSE TRUE Passed 2020-04-27 The data can be easily filtered on to find the data most relevant to your effort, such as dat_info %&gt;% filter(stringr::str_detect(location_types, &quot;state&quot;)) %&gt;% select(data_set_name, data_details) %&gt;% knitr::kable() %&gt;% kableExtra::kable_styling( bootstrap_options = c(&quot;striped&quot;,&quot;condensed&quot;, &quot;responsive&quot;)) %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;100%&quot;) data_set_name data_details covid19nytimes_states Open Source data from the New York Times on distribution of confirmed Covid-19 cases and deaths in the US States. For more, see https://www.nytimes.com/article/coronavirus-county-data-us.html or the readme at https://github.com/nytimes/covid-19-data. covid19nytimes_counties Open Source data from the New York Times on distribution of confirmed Covid-19 cases and deaths in the US by County. For more, see https://www.nytimes.com/article/coronavirus-county-data-us.html or the readme at https://github.com/nytimes/covid-19-data. CanadaC19_cases Open Source data from multiple public reporting data throughout Canada. For more, see https://github.com/ishaberry/Covid19Canada. covid19us Open Source data from COVID Tracking Project on the distribution of Covid-19 cases and deaths in the US. For more, see https://github.com/opencovid19-fr/data. 2.2 Downloading a dataset with get_covid19_dataset() Once you have determined the relevant dataset you want, you can download it with get_covid19_dataset(). For example nytimes_states &lt;- get_covid19_dataset(&quot;covid19nytimes_states&quot;) nytimes_states %&gt;% head() %&gt;% knitr::kable(format = &quot;html&quot;) %&gt;% kableExtra::kable_styling( bootstrap_options = c(&quot;striped&quot;,&quot;condensed&quot;, &quot;responsive&quot;)) date location location_type location_code location_code_type data_type value 2020-04-26 Alabama state 01 fips_code cases_total 6421 2020-04-26 Alabama state 01 fips_code deaths_total 219 2020-04-26 Alaska state 02 fips_code cases_total 339 2020-04-26 Alaska state 02 fips_code deaths_total 7 2020-04-26 Arizona state 04 fips_code cases_total 6526 2020-04-26 Arizona state 04 fips_code deaths_total 277 2.3 Examining controlled vocabulary with get_covid19_controlled_vocab() In our data standard, we have three types of controlled vocabulary - location_type, location_code_type, and data_type. To see what the current controlled vocabulary is (both to understand the fields and to see if we should add more), use get_covid19_controlled_vocab() as below: get_covid19_controlled_vocab(&quot;location_type&quot;) %&gt;% knitr::kable(format = &quot;html&quot;) %&gt;% kableExtra::kable_styling( bootstrap_options = c(&quot;striped&quot;,&quot;condensed&quot;, &quot;responsive&quot;)) location_type description continent continental scale country a country with soverign borders state a spatial area inside that country such as a state, province, canton, etc. county a spatial area demarcated within a state city a single municipality - the smallest spatial grain of government in a country canton the cantons of Switzerland and Principality of Liechtenstein (FL) get_covid19_controlled_vocab(&quot;location_code_type&quot;) %&gt;% knitr::kable(format = &quot;html&quot;) %&gt;% kableExtra::kable_styling( bootstrap_options = c(&quot;striped&quot;,&quot;condensed&quot;, &quot;responsive&quot;)) location_code_type description URL fips_code The federal code in US designating regions of governance https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt iso_3166 ISO 3166 is a standard published by the International Organization for Standardization (ISO) that defines codes for the names of countries, dependent territories, special areas of geographical interest, and their principal subdivisions (e.g., provinces or states). https://en.wikipedia.org/wiki/ISO_3166 iso_3166_2 ISO 3166-2 is part of the ISO 3166 standard published by the International Organization for Standardization (ISO), and defines codes for identifying the principal subdivisions (e.g., provinces or states) of all countries coded in ISO 3166-1. https://en.wikipedia.org/wiki/ISO_3166-2 get_covid19_controlled_vocab(&quot;data_type&quot;) %&gt;% knitr::kable(format = &quot;html&quot;) %&gt;% kableExtra::kable_styling( bootstrap_options = c(&quot;striped&quot;,&quot;condensed&quot;, &quot;responsive&quot;)) data_type description cases_new new confirmed Covid-19 cases during on the current date cases_total cumulative confirmed Covid-19 cases as of the current date recovered_total cumulative number of patients recovered as of the current date recovered_new new number of patients recovered on the current date deaths_new new deaths on the current date deaths_total cumulative deaths due to Covid-19 as of the current date tested_total cumulative number of tests performed as of the date hosp_new new hospitalizations on the current date hosp_current current number of hospitalized patients as of the current date icu_current number of hospitalized patients in ICUs as of the current date vent_current number of hospitalized patients requiring ventilation as of the current date "],
["packages-part-of-the-project.html", "Chapter 3 Packages Part of the Project", " Chapter 3 Packages Part of the Project covid19R - Our main package covid19nytimes - Accessing the NY Times State and County data covid19france - Providing data from opencovid19-fr "],
["building-a-new-data-package.html", "Chapter 4 Building a New Data Package 4.1 Before your start: 4.2 How should I divide the data? 4.3 Packages to use to help yourself out 4.4 Files to edit on start: 4.5 The meat of your task for the library 4.6 If you would like a local dataset to accompany this package 4.7 Documenting your functions and data 4.8 Vignettes 4.9 Tests 4.10 Files to edit and things to do for release to the public 4.11 Making your package a part of the Covid19R Project 4.12 Submitting to CRAN", " Chapter 4 Building a New Data Package So, you want to create an R data package if covid19 data for the project? Great! You’re welcome to create your own from scratch, or, we’ve created a package template for you to use - particularly useful to first-time package creators! For either case, let’s go through the steps you’ll need to follow, including some best practices, from start to letting us know it works, all the way to CRAN submission!! 4.1 Before your start: Choose a dataset! We’d advise just going with one for simplicity - particularly if this is your first time. If you’re interested in contributing, but don’t know where to start, we’re trying to keep track of data sources here. Please feel free to add more sources here as well, if you know of some! Use this package template to create your own github repo or start a repo with a package you’re creating from scratch. You can create it under your own user account, or, contact us if you would like to start the repo in the covid19R organization by filing an issue. Regardles, file an issue to let us and others know what you are working on with the pre-made Start a new package template! We want to support you, cheer you on, and provide any help you need! Keep a running documentation of usethis calls that you use to create the library in setupcode.R Take the steps listed here, and file an issue in your own repo, replacing each - with a - [ ] in order to create a checklist for creation and release! Also, that way, you can use the actual readme portion of this file as your README.Rmd! 4.2 How should I divide the data? You might be interested in making a package that brings in multiple different data sets for a given area. Or, the data source you’re accessing contains multiple different types of data, or data at different levels of spatial organization. Should you deploy these as one big long data set or multiple data sets. There can be different reasons for taking either path. In general, we advise you to think about, how will an end-user use a single data set? Assume that they have minimal information about your dataset initially (I mean, hopefully they won’t, but nuanced dataset details can be difficult to grasp at first), but want to create a clean, clear, accurate analysis or visualization. For example, the NY Times reports both state and county level data and multiple data types. In covid19nytimes, we deploy one state-level datas et and one county-level data set. This minimizes confusion and possible mistakes (summing county-level data = state level data, and if both were in one data set, mistakes could be made in over-aggregating and getting 2X the number of cases). Within each data set, however, multiple data types are reported, as they can be filtered or shown together, even. Other data sets will provide some more complexity. In the JHU data, for example, information for some countries is reported at the Province level, and for some countries, it’s at the country level. However, it’s one global dataset, and so the whole set is returned together. However, the location_type column clearly shows what is aggregated, what is not, and using a simple tidyr::separate() country and province-level data can be split for easier aggregation and display. In essence, how the raw data is structured will inform you how to split or not split the final tidy data. 4.3 Packages to use to help yourself out If this is your first time writing a package, there are a few packages that will help you greatly to develop your package. I’ll also presume you’re doing this within RStudio, which has a variety of tools to make your lives easier in building and deploying packages. devtools: This package is written to help you write packages. Period. We’ll reference a variety of tools that it supplies. usethis: This package has a variety of tools to setup elements of your package using standard techniques. testthat: This package will allow you to write tests and/or use the tests we are providing to ensure that your package will be compliant with the standards for the covid19R project. styler: use this to make your code cleaner and more readable roxygen2: This is the package we’ll be using for all documentation. 4.4 Files to edit on start: OK, you’re ready and raring to go. We’re going to write this as if you are using the template. Adapt as needed if you are rolling your own. .Rbuildignore: Sub in your r project name. Edit as needed. DESCRIPTION: see all caps notes. For the LICENSE, first use a standard license for R by using [the appropriate usethis license function] to add to your description and put it in setupcode.R. We recommend the MIT License. This covers your code. However, the data itself might have a different license. Make sure to add a link to it in the description, as well as include the most salient terms for the end-user. Be sure to add a link to the license in documentation for the dataset, if including it, as well and a link in the documentation for the refresh_*() functions described below. 4.5 The meat of your task for the library All packages in the covid19R have, at minimum, two functions. One function returns all of the information about the dataset in the package. The second function refreshes a dataset to the most current version. If there are multiple datasets per package, only one of the get_info functions is needed. However, each dataset should have its own refresh function. This is for two reasons. First, each dataset might require different code to parse it. Second, the covid19R data harvesting scripts use the names of your datasets to dynamically call the refresh functions. Along the way, there are a few other R helper files to setup in R. R/utils.R - put helper functions that you don’t want exposed to the user here. Note, we’ve seeded it with what you need to get a pipe from magrittr, as, we’re assuming you’re likely going to use this. If you’re a base-R coder, feel free to delete it from here and move on (and remove from the imports in DESCRIPTION). R/get_info_YOURPACKAGENAME - This function will return all of the salient info about each dataset that your package returns. We’ve set it up in the template using tibble::tribble() for ease of editing and adding new datasets (and imported tibble), but you are welcome to change this if you wish to reduce dependencies. The comments in the file lay out the information you need to provide, from dataset name to package name, to where the data comes from. Three columns ask for info from our controlled vocabulary - data types, location types, and spatial extent of dataset. If you have multiple entries for any of these, separate entries by a comma. This will make it easier for end-users to search through information about all datasets and find yours! If you have new types you need to add to our controlled vocabulary, file an issue with the appropriate template, and we’ll add it! We want to bring in all types of data! Remember, each dataset that your package provides needs one complete set of information. R/refresh_YOURPACKAGENAME - This is where you put your package dataset refresh methods. It should return a tidy dataset in the format discussed below. In general, functions for individual datasets should be named refresh_YOURPACKAGENAME() if you have just one dataset in this package and refresh_YOURPACKAGENAME_MOREINFO() if you have more than one. For example, refresh_covid19france() is a good for a package named covid19france package, if it only have one dataset. In the covid19nytimes package, there are two datasets, so, there is a refresh_covid19nytimes_states() and refresh_covid19nytimes_counties() function. Broadly, this function should scrape data from a source, and then reformat it into the Covid19R Project long format. In this format, every measurement is a single row. The minimal data specification for columns is as follows (and see also our documentation). You can have columns in addition to this (e.g., lat, long, race, sex, income, etc.), but you must include these in order to be a valid data set. We will test for them! date - The date in YYYY-MM-DD form location - The name of the location as provided by the data source. Nested locations are combined and separated by a ,, and can be split by tidyr::separate(), if you wish. location_type - The type of location using the covid19R controlled vocabulary. Nested locations are indicated by multiple location types being combined with a _ location_code - A standardized location code using a national or international standard. location_code_type The type of standardized location code being used according to the covid19R controlled vocabulary. data_type - the type of data in that given row. value - number of cases of each data type For different types, we employ a standardized vocabulary which you must conform to. See here for documentation. If you have a data type, location type, or location standard that we do not have, great! We are always looking to expand! Submit an issue and request that we add the new type! R/globals.R - As you edit your functions, you’ll have a lot of column names you’ll refer to. There are column names from our data standard. Column names for the dataset as your import and transform it. And perhaps more. In order to pass CRAN checks, these need to be declared as globals. Open up the globals.R file and add them. You’ll see we’ve already put in the standard columns as an example. If you have no idea what we’re talking about, do a build check, and you’ll see a number of global declaration errors. That’s what we’re talking about! 4.6 If you would like a local dataset to accompany this package It is often helpful to have a demo dataset to work with for a new user, rather than for them to have to refresh the whole thing. Also, sometimes data source standard change, and you will want to compare the new incoming data to what it previously looked like. For that reason, in the data-raw directory, we have provided a file DATASET.R which you can edit to use for each dataset you scrape to save a frozen version that can be deployed with your package. As it will be static and not updating, we recommend labelling it *_demo, as we have shown in the example. This is not required, but recommended. If you are not going to do this, feel free to delete the data-raw directory as well as R/data.R. 4.7 Documenting your functions and data We have left roxygen2 skeletons [in the template] (https://github.com/Covid19R/covid19_package_template) for you with the main functions. Fill them out! Make sure any additional public functions you generate are filled out as well! If you have created a demo dataset, use the provided R/data.R file to document it. Once your documentation is in place, build it using roxygen2 (or the dropdown in the RStudio Build tab). Fix any errors, and then continue! 4.8 Vignettes We highly recommend writing a package vignette or two. We have included a line in the setup.R to get you going. Your vignette should introduce the dataset(s), what is in it/them, and provide a compelling visualization. Make sure that the visualization has a date on it so that anyone looking at it can see what it is current to. 4.9 Tests We have provided two example tests using testthat which provide bare minimum checks in the directory tests and associated subdirectories. Edit and use these to make sure whatever incoming data from your source meets your expectations, particularly as you get this package ready to push to the public. Run the tests using the Tests option in the Build tab in RStudio. 4.10 Files to edit and things to do for release to the public Readme.Rmd: We have provided a skeleton of your readme within this file. Use it and fill it in as needed. Feel free to modify as you’d like. News.md: Sub in your R project name for the first release Make a pkgdown site! This can be as simple as running pkgdown::build_site(), pushing the update, and making sure your repo settings are set to put up the website. Add the URL to your README and your github repo Take a look at setupcode.R in the preparing for release section. We’ve included a number of checks for you to run to make sure the code follows best practices, is well styled, and for you to check against r-hub and other sources to make sure it works beyond just your computer! These will help you have a much better package that is more likely to go through any release process faster - particularly if you submit to CRAN! 4.11 Making your package a part of the Covid19R Project OK! You’re there! It works, and your build is more or less clean (at least, only notes). Close your issue about developing a new package and… file a new issue to onboard this package with the onboarding template! We’ll take a look, test it out, and if it’s ready, we’ll add it in! Nice work! (and if it’s not, we’ll help you fix it) 4.12 Submitting to CRAN Use RStudio to build check your package until there are no errors, warnings, or notes, even! Run the suite of devtools checks provided in setupcode.R. If you pass everything, use devtools to submit (it’s in the setupcode), as it will ask you additional questions. Make sure your cran-comments.md file is up to date with info from your final check! "],
["guidance-for-writing-package-vignettes.html", "Chapter 5 Guidance for Writing Package Vignettes", " Chapter 5 Guidance for Writing Package Vignettes Here is a review of existing methods. "],
["unit-tests-for-data-packages.html", "Chapter 6 Unit Tests for Data Packages 6.1 Unit testing in R 6.2 Building a unit testing within a function 6.3 Setting unit testing with the testthat package", " Chapter 6 Unit Tests for Data Packages When developing a package (or generally production pipeline), unit testing is a powerful tool for quality control. It enables us to test the package functionality and outputs in different stages and set alerts when something went wrong or not according to the expectations. In the context of the Covid19R packages, having unit testing is critical to ensure the continuous integration (CI) of the data automation pipeline. 6.1 Unit testing in R There is more than one method for creating a unit testing in R depending on the functionality and type of workflow. For the Covid19R data packages, we recommend to set the following unit testing: Function - set tests within the function that pull the raw data Build - create a set of unit testing that run during the build of the package Github Actions - integrate those tests on the package automation workflow on Github Actions. This will allow triggering email upon failure 6.2 Building a unit testing within a function Setting a unit testing within a function is straightforward and based on the following workflow: Define the characteristics of the expected value of the function (or a specific part of it). For example, if you are pulling data from an external source (API, Github repo, web scraping, etc.), the expected characteristics of the data are the number of columns, their names, the minimum number of raws, classes of each column (e.g., numeric, character, Date, etc.) Set test (or tests to evaluate if those characteristics are exists Define a set of actions if the test is fail Let’s take, for example, the data_refresh function from the covid19swiss package: #----------------------------------------- # covid19swiss pulling Raw data #----------------------------------------- data_refresh &lt;- function(){ #-------------- Setting -------------- files_list &lt;- swiss_map &lt;- df_raw &lt;- NULL #-------------- Functions -------------- `%&gt;%` &lt;- magrittr::`%&gt;%` #-------------- Github list of files -------------- files_list &lt;- read.csv(&quot;https://raw.githubusercontent.com/Covid19R/covid19swiss/master/csv/files_list.csv&quot;, stringsAsFactors = FALSE) #-------------- Test 1 - checking structure of the csv files list -------------- if(is.null(files_list)){ stop(&quot;The files_list is NULL&quot;) } else if(ncol(files_list) != 1){ stop(&quot;The number of the files_list table is not valid&quot;) } else if(nrow(files_list) != 27){ stop(&quot;The number of files on the files_list table is not valid&quot;) } #-------------- Pulling the map data -------------- swiss_map &lt;- rnaturalearth::ne_states(country = &quot;Switzerland&quot;, returnclass = &quot;sf&quot;) %&gt;% dplyr::mutate(canton = substr(gn_a1_code, 4,5)) %&gt;% dplyr::select(canton, gn_a1_code) %&gt;% as.data.frame() swiss_map$geometry &lt;- NULL #-------------- Pulling the raw data -------------- df_raw &lt;- lapply(1:nrow(files_list), function(i){ f &lt;- files_list$x[i] print(f) df &lt;- read.csv(paste(&quot;https://raw.githubusercontent.com/openZH/covid_19/master/fallzahlen_kanton_total_csv_v2/&quot;, gsub(&#39;&quot;&#39;, &#39;&#39;, f), sep = &quot;&quot;), stringsAsFactors = FALSE) return(df) }) %&gt;% dplyr::bind_rows() #-------------- Test 2 - checking structure of the raw data -------------- if(is.null(df_raw)){ stop(&quot;The raw data is empty&quot;) } else if(ncol(df_raw) != 17){ stop(&quot;The number of columns is not aligned the expected number of columns&quot;) } else if(any(!names(df_raw) %in% c(&quot;date&quot;, &quot;time&quot;, &quot;abbreviation_canton_and_fl&quot;, &quot;ncumul_tested&quot;, &quot;ncumul_conf&quot;, &quot;new_hosp&quot;, &quot;current_hosp&quot;, &quot;current_icu&quot;, &quot;current_vent&quot;, &quot;ncumul_released&quot;, &quot;ncumul_deceased&quot;, &quot;source&quot;, &quot;ncumul_confirmed_non_resident&quot;, &quot;current_hosp_non_resident&quot;, &quot;ncumul_ICF&quot;, &quot;TotalPosTests1&quot;, &quot;ninst_ICU_intub&quot;))){ stop(&quot;The columns names are not aligned the expected names&quot;) } #-------------- Cleaning the data -------------- head(df_raw) covid19swiss &lt;- df_raw %&gt;% dplyr::mutate(date = as.Date(date), canton = abbreviation_canton_and_fl) %&gt;% dplyr::group_by(date, canton) %&gt;% dplyr::summarise(total_tested = sum(ncumul_tested, na.rm = any(!is.na(ncumul_tested))), total_confirmed = sum(ncumul_conf, na.rm = any(!is.na(ncumul_tested))), new_hosp = sum(new_hosp, na.rm = any(!is.na(new_hosp))), current_hosp = sum(current_hosp, na.rm = any(!is.na(current_hosp))), current_icu = sum(current_icu, na.rm = any(!is.na(current_icu))), current_vent = sum(current_vent, na.rm = any(!is.na(current_vent))), total_recovered = sum(ncumul_released, na.rm = any(!is.na(ncumul_released))), total_death = sum(ncumul_deceased, na.rm = any(!is.na(ncumul_deceased)))) %&gt;% tidyr::pivot_longer(c(-date, - canton), names_to = &quot;data_type&quot;, values_to = &quot;value&quot;) %&gt;% dplyr::left_join(swiss_map, by = &quot;canton&quot;) %&gt;% dplyr::mutate(location = canton, location_type = ifelse(canton == &quot;FL&quot;, &quot;Principality of Liechtenstein&quot;, &quot;Canton of Switzerland&quot;), location_code = gn_a1_code, location_code_type = &quot;gn_a1_code&quot;) %&gt;% dplyr::select(date, location, location_type, location_code, location_code_type, data_type, value) %&gt;% as.data.frame() head(covid19swiss) #-------------- Test 3 - checking the stracture of the new data -------------- if(ncol(covid19swiss) != 7){ stop(&quot;The number of columns is not align with the expected one (7)&quot;) } else if(nrow(covid19swiss) &lt; 8200) { stop(&quot;The number of rows is not align with the expected one&quot;) } else if(min(covid19swiss$date) != as.Date(&quot;2020-02-25&quot;)){ stop(&quot;Stop, the starting date is not Feb 25&quot;) } #-------------- Pulling the Github csv version-------------- git_df &lt;- read.csv(&quot;https://raw.githubusercontent.com/Covid19R/covid19swiss/master/csv/covid19swiss.csv&quot;, stringsAsFactors = FALSE) git_df$date &lt;- as.Date(git_df$date) #-------------- Test 4 - checking the stracture of the Github data -------------- if(ncol(git_df) != 7){ stop(&quot;The number of columns is not align with the expected one (7)&quot;) } else if(nrow(git_df) &lt; 8200) { stop(&quot;The number of rows is not align with the expected one&quot;) } else if(min(git_df$date) != as.Date(&quot;2020-02-25&quot;)){ stop(&quot;Stop, the starting date is not Feb 25&quot;) } if(nrow(covid19swiss) &gt; nrow(git_df)){ print(&quot;Updates available&quot;) usethis::use_data(covid19swiss, overwrite = TRUE) write.csv(covid19swiss, &quot;csv/covid19swiss.csv&quot;, row.names = FALSE) print(&quot;The covid19swiss dataset was updated&quot;) } else { print(&quot;Updates are not available&quot;) } return(print(&quot;Done...&quot;)) } This function is doing to following: Pulling a csv file with a list of the raw data files names Pulling the raw data Pulling the most recent data available on the Github (Dev) version of the package Comparing between the two datasets and testing if new data is available on the raw data If new data is available, refresh the Github version of the package The list below describes several scenarios that could cause a failure in the workflow of the function and the corresponding tests: This file list could potentially change whenever new data added or removed. In the case of covid19swiss dataset, we expect 27 files (26 files for Switzerland cantons and one for the Principality of Liechtenstein). The following code will test if the structure of the file aligns with our expectation: #-------------- Test 1 - checking structure of the csv files list -------------- if(is.null(files_list)){ stop(&quot;The files_list is NULL&quot;) } else if(ncol(files_list) != 1){ stop(&quot;The number of the files_list table is not valid&quot;) } else if(nrow(files_list) != 27){ stop(&quot;The number of files on the files_list table is not valid&quot;) } When pulling data from an external resource that is not in our control, the function most likely to fail (or worse, build the data with the wrong fields) whenever the data is changing. Therefore, we will run the following tests to ensure that we are pulling the right data: Check if the return object is empty Test if the number of columns is aligned our expectations (17) Check if the names of the columns match the expected names #-------------- Test 2 - checking structure of the raw data -------------- if(is.null(df_raw)){ stop(&quot;The raw data is empty&quot;) } else if(ncol(df_raw) != 17){ stop(&quot;The number of columns is not aligned the expected number of columns&quot;) } else if(any(!names(df_raw) %in% c(&quot;date&quot;, &quot;time&quot;, &quot;abbreviation_canton_and_fl&quot;, &quot;ncumul_tested&quot;, &quot;ncumul_conf&quot;, &quot;new_hosp&quot;, &quot;current_hosp&quot;, &quot;current_icu&quot;, &quot;current_vent&quot;, &quot;ncumul_released&quot;, &quot;ncumul_deceased&quot;, &quot;source&quot;, &quot;ncumul_confirmed_non_resident&quot;, &quot;current_hosp_non_resident&quot;, &quot;ncumul_ICF&quot;, &quot;TotalPosTests1&quot;, &quot;ninst_ICU_intub&quot;))){ stop(&quot;The columns names are not aligned the expected names&quot;) } Last but not least, we want to test the structure of the data after cleaning and preprocessing the raw data with the following tests: Number of columns Number of raws greater than some threshold Starting date in the data set aligned the expectation #-------------- Test 3 - checking the stracture of the new data -------------- if(ncol(covid19swiss) != 7){ stop(&quot;The number of columns is not align with the expected one (7)&quot;) } else if(nrow(covid19swiss) &lt; 8200) { stop(&quot;The number of rows is not align with the expected one&quot;) } else if(min(covid19swiss$date) != as.Date(&quot;2020-02-25&quot;)){ stop(&quot;Stop, the starting date is not Feb 25&quot;) } 6.3 Setting unit testing with the testthat package The second type of unit testing conducts on the package level. It enables to test a wider range of the package functionality. In R, the most common approach for creating such type of unit testing is with the testthat package. Using this package allows you to set multiple tests that will execute whenever running the build check (R CMD check). This ensures that you will identify problems before submitting the package to CRAN (assuming you build good tests!). usethis::use_testthat() "],
["preparing-and-submitting-to-cran.html", "Chapter 7 Preparing and Submitting to CRAN 7.1 A Checklist for pre-CRAN submission 7.2 Guidance on executing your checklist.", " Chapter 7 Preparing and Submitting to CRAN 7.1 A Checklist for pre-CRAN submission Before submitting to CRAN, file an issue on your package with the following checklist. Fill it out as you go along with the preparation to submit steps outlined below. - [ ] Update the README.Rmd and re-knit - [ ] Update the package site - [ ] Update the package vignette, if you have one - [ ] Update the package NEWS.md - [ ] Make sure you pass build check - [ ] Check your package with styler - [ ] Check your package with goodpractice::gp() - [ ] Run devtools checks and make sure you pass - [ ] Update the package cran-comments.md - [ ] Submit to CRAN with devtools::release() 7.2 Guidance on executing your checklist. Before submitting to CRAN, we’d ask that you Make sure you pass build check (Check in the RMarkdown Build tab) with no errors, no warnings, no notes. Update any vignettes with basic examples, the NEWS.md file with what is being released (or any changes from previous versions), and the README.Rmd with any final details. Build a pkgdown website to help users. Make sure to link to it in your github repo. # make a pkgdown website! pkgdown::build_site() Check your code to make sure it is is easy to read and well styled. This can be done easily with the styler package. styler::style_pkg() Take a final check through to make sure your package is obeying best-practices using the goodpractice library. goodpractice::gp() Execute final checks. First, make sure after making revisions from the above, you pass Build Check again. Then, walk through the following final checks provided by devtools. # for release - checks! devtools::check_win_release() devtools::release_checks() devtools::spell_check() devtools::check_rhub() Release! Again, using devtools (which will check you)! #------------- # Release #### #------------- devtools::release() "],
["data-format-standard.html", "Chapter 8 Data Format Standard", " Chapter 8 Data Format Standard The minimal tidy data format that all packages need to incorporate looks like the following. This is a bare-bones minimum. Additional data columns are possible and welcomed, but, for inter-operability, the following are required. x date location location_type location_code location_code_type data_type value 2020-01-21 Washington state 53 fips_code cases_total 1 2020-01-21 Washington state 53 fips_code deaths_total 0 2020-01-22 Washington state 53 fips_code cases_total 1 2020-01-22 Washington state 53 fips_code deaths_total 0 2020-01-23 Washington state 53 fips_code cases_total 1 |2020-01-23 |Washington |state |53 |fips_code |deaths_total | 0| The data columns are as follows: date - The date in YYYY-MM-DD form location - The name of the location as provided by the data source. The counties dataset provides county and state. They are combined and separated by a ,, and can be split by tidyr::separate(), if you wish. location_type - The type of location using the covid19R controlled vocabulary. Nested locations are indicated by multiple location types being combined with a `_ location_code - A standardized location code using a national or international standard. In this case, FIPS state or county codes. See https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code and https://en.wikipedia.org/wiki/FIPS_county_code for more location_code_type The type of standardized location code being used according to the covid19R controlled vocabulary. Here we use fips_code data_type - the type of data in that given row. Includes total_cases and total_deaths, cumulative measures of both. value - number of cases of each data type "],
["standardized-vocabulary.html", "Chapter 9 Standardized Vocabulary 9.1 Adding To the Standardized Vocabularies 9.2 Current Location Types 9.3 Current Location Code Types 9.4 Current Data Types", " Chapter 9 Standardized Vocabulary While many of the columns (e.g., location, standardized_location) are variable in their output, the types that are used to describe them are drawn from a standardized vocabulary. Here are the data standards for option 2 - long, with explanation for each. - date: YYYY-MM-DD - location_type: Continent, Country, State, Province - location_code_type: fips_code, iso_a3 - data_type: For temporally dynamic data types, use *_new, *_total, or *_current to represent new values for the current day versus cummulative values versus current values of things that can increase or decrease. 9.1 Adding To the Standardized Vocabularies Below, we list many of the current entries in our standardized vocabulary. If you do not see what you need here, file an issue in the covid19R repo using one of the premade templates, and we will work on adding it. 9.2 Current Location Types location_type description continent continental scale country a country with soverign borders state a spatial area inside that country such as a state, province, canton, etc. county a spatial area demarcated within a state city a single municipality - the smallest spatial grain of government in a country canton the cantons of Switzerland and Principality of Liechtenstein (FL) 9.3 Current Location Code Types location_code_type description URL fips_code The federal code in US designating regions of governance https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt iso_3166 ISO 3166 is a standard published by the International Organization for Standardization (ISO) that defines codes for the names of countries, dependent territories, special areas of geographical interest, and their principal subdivisions (e.g., provinces or states). https://en.wikipedia.org/wiki/ISO_3166 iso_3166_2 ISO 3166-2 is part of the ISO 3166 standard published by the International Organization for Standardization (ISO), and defines codes for identifying the principal subdivisions (e.g., provinces or states) of all countries coded in ISO 3166-1. https://en.wikipedia.org/wiki/ISO_3166-2 9.4 Current Data Types data_type description cases_new new confirmed Covid-19 cases during on the current date cases_total cumulative confirmed Covid-19 cases as of the current date recovered_total cumulative number of patients recovered as of the current date recovered_new new number of patients recovered on the current date deaths_new new deaths on the current date deaths_total cumulative deaths due to Covid-19 as of the current date tested_total cumulative number of tests performed as of the date hosp_new new hospitalizations on the current date hosp_current current number of hospitalized patients as of the current date icu_current number of hospitalized patients in ICUs as of the current date vent_current number of hospitalized patients requiring ventilation as of the current date "],
["standardized-package-functions.html", "Chapter 10 Standardized Package Functions 10.1 Getting Information 10.2 Obtaining fresh data", " Chapter 10 Standardized Package Functions All packages that are part of the Covid19R project have two functions at their core. These functions are necessary in order to hook the package up to the Covid19R data aggregator - and/or it could mean that for users interested in individual packages instead of pulling data from the covid19R package, they’ll know their way around your data package quickly! 10.1 Getting Information The get_info_*() function returns all of the salient info about each dataset in a package. It ends in the name of the package, e.g., get_info_covid19nytimes() for the covid19nytimes package. Each package only has one get_info_*() function. It returns the following fields: data_set_name - The name of the data set. package_name - The name of the package the data set lives in. function_to_get_data - The function in the package that is used to get the data. data_details - A detailed description of the data set. data_url - A URL for where the data comes from. license_url - A URL for the license for usage of the data. PLEASE READ THIS. data_types - What kinds of data is here? cases, deaths, hospital beds, etc. location_types - What types of locations are represented in the data, e.g., States, Countries, etc. spatial_extent - How large of an area does the data set cover? A single country? A continent? The globe? has_geospatial_info - Does the data set have explicit geospatial information (e.g., latitude and longtitude) such that it can be easily converted into an sf object or otherwise? For example covid19us::get_info_covid19us() %&gt;% knitr::kable(format = &quot;html&quot;) %&gt;% kableExtra::kable_styling( bootstrap_options = c(&quot;striped&quot;,&quot;condensed&quot;, &quot;responsive&quot;)) data_set_name package_name function_to_get_data data_details data_url license_url data_types location_types spatial_extent has_geospatial_info covid19us covid19us refresh_covid19us Open Source data from COVID Tracking Project on the distribution of Covid-19 cases and deaths in the US. For more, see https://github.com/opencovid19-fr/data. https://covidtracking.com/api https://github.com/aedobbyn/covid19us/blob/master/LICENSE.md positive, negative, pending, hospitalized_currently, hospitalized_cumulative, in_icu_currently, in_icu_cumulative, on_ventilator_currently, on_ventilator_cumulative, recovered, death, hospitalized, total, total_test_results, death_increase, hospitalized_increase, negative_increase, positive_increase, total_test_results_increase state country FALSE 10.2 Obtaining fresh data Each data set has its own refresh_*() function. It can either be refresh_PACKAGENAME() if the data package only supplies one data set. For example refresh_covid19france(). Or, if there are multiple data sets in a package, refresh_PACKAGENAME_MOREINFO() where PACKAGENAME_MOREINFO is the full name of a data set. For example refresh_covid19nytimes_states() and refresh_covid19nytimes_counties() return two different data sets from the covid19nytimes data package. covid19nytimes::refresh_covid19nytimes_states() %&gt;% head() %&gt;% knitr::kable(&quot;html&quot;) %&gt;% kableExtra::kable_styling( bootstrap_options = c(&quot;striped&quot;,&quot;condensed&quot;, &quot;responsive&quot;)) date location location_type location_code location_code_type data_type value 2020-04-29 Alabama state 01 fips_code cases_total 6925 2020-04-29 Alabama state 01 fips_code deaths_total 262 2020-04-29 Alaska state 02 fips_code cases_total 353 2020-04-29 Alaska state 02 fips_code deaths_total 7 2020-04-29 Arizona state 04 fips_code cases_total 7202 2020-04-29 Arizona state 04 fips_code deaths_total 308 "],
["references.html", "References", " References "]
]
